{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9JaNNjmKQ2l"
   },
   "source": [
    "**Samson Zhang note book**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DGF_-oTmEk0d",
    "outputId": "6640f334-c6f2-45f0-82a1-bc11ae3ffa07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0          1       0       0       0       0       0       0       0       0   \n",
      "1          0       0       0       0       0       0       0       0       0   \n",
      "2          1       0       0       0       0       0       0       0       0   \n",
      "3          4       0       0       0       0       0       0       0       0   \n",
      "4          0       0       0       0       0       0       0       0       0   \n",
      "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "41995      0       0       0       0       0       0       0       0       0   \n",
      "41996      1       0       0       0       0       0       0       0       0   \n",
      "41997      7       0       0       0       0       0       0       0       0   \n",
      "41998      6       0       0       0       0       0       0       0       0   \n",
      "41999      9       0       0       0       0       0       0       0       0   \n",
      "\n",
      "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "0           0  ...         0         0         0         0         0   \n",
      "1           0  ...         0         0         0         0         0   \n",
      "2           0  ...         0         0         0         0         0   \n",
      "3           0  ...         0         0         0         0         0   \n",
      "4           0  ...         0         0         0         0         0   \n",
      "...       ...  ...       ...       ...       ...       ...       ...   \n",
      "41995       0  ...         0         0         0         0         0   \n",
      "41996       0  ...         0         0         0         0         0   \n",
      "41997       0  ...         0         0         0         0         0   \n",
      "41998       0  ...         0         0         0         0         0   \n",
      "41999       0  ...         0         0         0         0         0   \n",
      "\n",
      "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "0             0         0         0         0         0  \n",
      "1             0         0         0         0         0  \n",
      "2             0         0         0         0         0  \n",
      "3             0         0         0         0         0  \n",
      "4             0         0         0         0         0  \n",
      "...         ...       ...       ...       ...       ...  \n",
      "41995         0         0         0         0         0  \n",
      "41996         0         0         0         0         0  \n",
      "41997         0         0         0         0         0  \n",
      "41998         0         0         0         0         0  \n",
      "41999         0         0         0         0         0  \n",
      "\n",
      "[42000 rows x 785 columns]\n",
      "Iteration: 0, Accuracy: 0.1468780487804878\n",
      "Iteration: 10, Accuracy: 0.11387804878048781\n",
      "Iteration: 20, Accuracy: 0.123\n",
      "Iteration: 30, Accuracy: 0.18502439024390244\n",
      "Iteration: 40, Accuracy: 0.2143170731707317\n",
      "Iteration: 50, Accuracy: 0.30029268292682926\n",
      "Iteration: 60, Accuracy: 0.33251219512195124\n",
      "Iteration: 70, Accuracy: 0.3375365853658537\n",
      "Iteration: 80, Accuracy: 0.3651219512195122\n",
      "Iteration: 90, Accuracy: 0.41048780487804876\n",
      "Iteration: 100, Accuracy: 0.48104878048780486\n",
      "Iteration: 110, Accuracy: 0.5692439024390243\n",
      "Iteration: 120, Accuracy: 0.6254634146341463\n",
      "Iteration: 130, Accuracy: 0.6625365853658537\n",
      "Iteration: 140, Accuracy: 0.6954634146341463\n",
      "Iteration: 150, Accuracy: 0.7250243902439024\n",
      "Iteration: 160, Accuracy: 0.7513170731707317\n",
      "Iteration: 170, Accuracy: 0.7721463414634147\n",
      "Iteration: 180, Accuracy: 0.7886585365853659\n",
      "Iteration: 190, Accuracy: 0.8031463414634147\n",
      "Iteration: 200, Accuracy: 0.8141951219512195\n",
      "Iteration: 210, Accuracy: 0.8225121951219512\n",
      "Iteration: 220, Accuracy: 0.8290731707317073\n",
      "Iteration: 230, Accuracy: 0.8358780487804878\n",
      "Iteration: 240, Accuracy: 0.8418048780487805\n",
      "Iteration: 250, Accuracy: 0.8468048780487805\n",
      "Iteration: 260, Accuracy: 0.8507073170731707\n",
      "Iteration: 270, Accuracy: 0.8542926829268292\n",
      "Iteration: 280, Accuracy: 0.8572926829268293\n",
      "Iteration: 290, Accuracy: 0.8603414634146341\n",
      "Iteration: 300, Accuracy: 0.8630975609756097\n",
      "Iteration: 310, Accuracy: 0.8652439024390244\n",
      "Iteration: 320, Accuracy: 0.8672926829268293\n",
      "Iteration: 330, Accuracy: 0.87\n",
      "Iteration: 340, Accuracy: 0.8719512195121951\n",
      "Iteration: 350, Accuracy: 0.8733170731707317\n",
      "Iteration: 360, Accuracy: 0.8751463414634146\n",
      "Iteration: 370, Accuracy: 0.8765853658536585\n",
      "Iteration: 380, Accuracy: 0.8779512195121951\n",
      "Iteration: 390, Accuracy: 0.8791707317073171\n",
      "Iteration: 400, Accuracy: 0.880609756097561\n",
      "Iteration: 410, Accuracy: 0.8819024390243903\n",
      "Iteration: 420, Accuracy: 0.8829512195121951\n",
      "Iteration: 430, Accuracy: 0.8839756097560976\n",
      "Iteration: 440, Accuracy: 0.8847317073170732\n",
      "Iteration: 450, Accuracy: 0.8854390243902439\n",
      "Iteration: 460, Accuracy: 0.8864390243902439\n",
      "Iteration: 470, Accuracy: 0.8877073170731707\n",
      "Iteration: 480, Accuracy: 0.8884390243902439\n",
      "Iteration: 490, Accuracy: 0.8892439024390244\n",
      "Development Set Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Read data from CSV file\n",
    "data = pd.read_csv('train3.csv')\n",
    "print(data)\n",
    "\n",
    "# Convert data to numpy array and shuffle rows\n",
    "data = np.array(data)\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# Separate data into development and training sets\n",
    "data_dev = data[0:1000].T\n",
    "Y_dev = data_dev[0]\n",
    "X_dev = data_dev[1:].astype(float) / 255.0  # Normalize X_dev\n",
    "\n",
    "data_train = data[1000:].T\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:].astype(float) / 255.0  # Normalize X_train\n",
    "_, m_train = X_train.shape\n",
    "\n",
    "def ReLU(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def softmax(Z):\n",
    "    expZ = np.exp(Z - np.max(Z))  # Avoid overflow\n",
    "    return expZ / np.sum(expZ, axis=0, keepdims=True)\n",
    "\n",
    "def init_params():\n",
    "    W1 = np.random.randn(10, 784) * 0.01\n",
    "    b1 = np.zeros((10, 1))\n",
    "    W2 = np.random.randn(10, 10) * 0.01\n",
    "    b2 = np.zeros((10, 1))\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def one_hot(Y, num_classes):\n",
    "    one_hot_Y = np.zeros((num_classes, Y.size))\n",
    "    one_hot_Y[Y, np.arange(Y.size)] = 1\n",
    "    return one_hot_Y\n",
    "\n",
    "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
    "    one_hot_Y = one_hot(Y.astype(int), num_classes=10)\n",
    "    m = Y.size\n",
    "\n",
    "    dZ2 = A2 - one_hot_Y\n",
    "    dW2 = (1 / m) * dZ2.dot(A1.T)\n",
    "    db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = W2.T.dot(dZ2) * (Z1 > 0)\n",
    "    dW1 = (1 / m) * dZ1.dot(X.T)\n",
    "    db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 -= alpha * dW1\n",
    "    b1 -= alpha * db1\n",
    "    W2 -= alpha * dW2\n",
    "    b2 -= alpha * db2\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, axis=0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        if i % 10 == 0:\n",
    "            predictions = get_predictions(A2)\n",
    "            accuracy = get_accuracy(predictions, Y)\n",
    "            print(f\"Iteration: {i}, Accuracy: {accuracy}\")\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# Train the model\n",
    "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, alpha=0.1, iterations=500)\n",
    "\n",
    "# Evaluate on development set\n",
    "def make_predictions(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    return predictions\n",
    "\n",
    "dev_predictions = make_predictions(X_dev, W1, b1, W2, b2)\n",
    "accuracy_dev = get_accuracy(dev_predictions, Y_dev)\n",
    "print(f\"Development Set Accuracy: {accuracy_dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LNe41VUHe0N"
   },
   "source": [
    "**500 forward/backward propagation steps and learning rate α = 0.1(accuracy of the trained network should be about 82 to 85 percent.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w9Ca6ZOyDyvq",
    "outputId": "32e729c7-417d-4d02-f3bb-41bec7bd545f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n",
      "Iteration 0: Development Set Accuracy = 0.187\n",
      "Iteration 100: Development Set Accuracy = 0.635\n",
      "Iteration 200: Development Set Accuracy = 0.751\n",
      "Iteration 300: Development Set Accuracy = 0.791\n",
      "Iteration 400: Development Set Accuracy = 0.816\n",
      "Final Development Set Accuracy: 0.835\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load MNIST dataset\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# Flatten and scale the grayscale values to [0, 1]\n",
    "X_train = X_train.reshape(X_train.shape[0], -1).astype('float32') / 255.0\n",
    "\n",
    "# Define functions\n",
    "def init_params():\n",
    "    W1 = np.random.rand(10, 784) - 0.5\n",
    "    b1 = np.random.rand(10, 1) - 0.5\n",
    "    W2 = np.random.rand(10, 10) - 0.5\n",
    "    b2 = np.random.rand(10, 1) - 0.5\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def ReLU(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def softmax(Z):\n",
    "    exp_Z = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n",
    "    return exp_Z / np.sum(exp_Z, axis=0, keepdims=True)\n",
    "\n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, axis=0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "# Load development set\n",
    "X_dev, Y_dev = X_train[:1000].T, Y_train[:1000]\n",
    "X_train, Y_train = X_train[1000:].T, Y_train[1000:]\n",
    "_, m_train = X_train.shape\n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "        one_hot_Y = np.zeros(A2.shape)\n",
    "        one_hot_Y[Y, np.arange(m_train)] = 1\n",
    "        dZ2 = A2 - one_hot_Y\n",
    "        dW2 = 1 / m_train * dZ2.dot(A1.T)\n",
    "        db2 = 1 / m_train * np.sum(dZ2, axis=1, keepdims=True)\n",
    "        dZ1 = W2.T.dot(dZ2) * (Z1 > 0)\n",
    "        dW1 = 1 / m_train * dZ1.dot(X.T)\n",
    "        db1 = 1 / m_train * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "        W1 -= alpha * dW1\n",
    "        b1 -= alpha * db1\n",
    "        W2 -= alpha * dW2\n",
    "        b2 -= alpha * db2\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            _, _, _, A2_dev = forward_prop(W1, b1, W2, b2, X_dev)\n",
    "            predictions_dev = get_predictions(A2_dev)\n",
    "            acc_dev = get_accuracy(predictions_dev, Y_dev)\n",
    "            print(f\"Iteration {i}: Development Set Accuracy = {acc_dev}\")\n",
    "\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# Train the model\n",
    "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, alpha=0.1, iterations=500)\n",
    "\n",
    "# Calculate accuracy on development set\n",
    "_, _, _, A2_dev = forward_prop(W1, b1, W2, b2, X_dev)\n",
    "predictions_dev = get_predictions(A2_dev)\n",
    "acc_dev = get_accuracy(predictions_dev, Y_dev)\n",
    "print(f\"Final Development Set Accuracy: {acc_dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTZ7saqhIbEN"
   },
   "source": [
    "**In the hope to get a higher accuracy, enlarge the neural network, by adding an additional hidden layer and adding more interior nodes. Try 20 nodes in the first and 10 nodes in the second hidden layer. Run propagation with 1000 steps and learning rate α = 0.1. How much improvement does the larger network provide?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PLWIjKOLKH-L",
    "outputId": "dc014648-e824-4aa2-a3da-1c5995a0282b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Development Set Accuracy = 0.108\n",
      "Iteration 100: Development Set Accuracy = 0.731\n",
      "Iteration 200: Development Set Accuracy = 0.811\n",
      "Iteration 300: Development Set Accuracy = 0.828\n",
      "Iteration 500: Development Set Accuracy = 0.86\n",
      "Iteration 600: Development Set Accuracy = 0.868\n",
      "Iteration 700: Development Set Accuracy = 0.874\n",
      "Iteration 800: Development Set Accuracy = 0.877\n",
      "Iteration 900: Development Set Accuracy = 0.882\n",
      "Final Development Set Accuracy: 0.887\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load MNIST dataset\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# Flatten and scale the grayscale values to [0, 1]\n",
    "X_train = X_train.reshape(X_train.shape[0], -1).astype('float32') / 255.0\n",
    "\n",
    "# Define functions\n",
    "def init_params():\n",
    "    W1 = np.random.rand(20, 784) - 0.5\n",
    "    b1 = np.random.rand(20, 1) - 0.5\n",
    "    W2 = np.random.rand(10, 20) - 0.5\n",
    "    b2 = np.random.rand(10, 1) - 0.5\n",
    "    W3 = np.random.rand(10, 10) - 0.5\n",
    "    b3 = np.random.rand(10, 1) - 0.5\n",
    "    return W1, b1, W2, b2, W3, b3\n",
    "\n",
    "def ReLU(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def softmax(Z):\n",
    "    exp_Z = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n",
    "    return exp_Z / np.sum(exp_Z, axis=0, keepdims=True)\n",
    "\n",
    "def forward_prop(W1, b1, W2, b2, W3, b3, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = ReLU(Z2)\n",
    "    Z3 = W3.dot(A2) + b3\n",
    "    A3 = softmax(Z3)\n",
    "    return Z1, A1, Z2, A2, Z3, A3\n",
    "\n",
    "def get_predictions(A3):\n",
    "    return np.argmax(A3, axis=0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "# Load development set\n",
    "X_dev, Y_dev = X_train[:1000].T, Y_train[:1000]\n",
    "X_train, Y_train = X_train[1000:].T, Y_train[1000:]\n",
    "_, m_train = X_train.shape\n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    W1, b1, W2, b2, W3, b3 = init_params()\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2, Z3, A3 = forward_prop(W1, b1, W2, b2, W3, b3, X)\n",
    "        one_hot_Y = np.zeros(A3.shape)\n",
    "        one_hot_Y[Y, np.arange(m_train)] = 1\n",
    "        dZ3 = A3 - one_hot_Y\n",
    "        dW3 = 1 / m_train * dZ3.dot(A2.T)\n",
    "        db3 = 1 / m_train * np.sum(dZ3, axis=1, keepdims=True)\n",
    "        dZ2 = W3.T.dot(dZ3) * (Z2 > 0)\n",
    "        dW2 = 1 / m_train * dZ2.dot(A1.T)\n",
    "        db2 = 1 / m_train * np.sum(dZ2, axis=1, keepdims=True)\n",
    "        dZ1 = W2.T.dot(dZ2) * (Z1 > 0)\n",
    "        dW1 = 1 / m_train * dZ1.dot(X.T)\n",
    "        db1 = 1 / m_train * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "        W1 -= alpha * dW1\n",
    "        b1 -= alpha * db1\n",
    "        W2 -= alpha * dW2\n",
    "        b2 -= alpha * db2\n",
    "        W3 -= alpha * dW3\n",
    "        b3 -= alpha * db3\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            _, _, _, _, _, A3_dev = forward_prop(W1, b1, W2, b2, W3, b3, X_dev)\n",
    "            predictions_dev = get_predictions(A3_dev)\n",
    "            acc_dev = get_accuracy(predictions_dev, Y_dev)\n",
    "            print(f\"Iteration {i}: Development Set Accuracy = {acc_dev}\")\n",
    "\n",
    "    return W1, b1, W2, b2, W3, b3\n",
    "\n",
    "# Train the model\n",
    "W1, b1, W2, b2, W3, b3 = gradient_descent(X_train, Y_train, alpha=0.1, iterations=1000)\n",
    "\n",
    "# Calculate accuracy on development set\n",
    "_, _, _, _, _, A3_dev = forward_prop(W1, b1, W2, b2, W3, b3, X_dev)\n",
    "predictions_dev = get_predictions(A3_dev)\n",
    "acc_dev = get_accuracy(predictions_dev, Y_dev)\n",
    "print(f\"Final Development Set Accuracy: {acc_dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WiAgroNLOpxU"
   },
   "source": [
    "**This larger network with more nodes and an additional hidden layer should improve accuracy compared to the previous smaller network. The printout during training will show the development set accuracy at different iterations, providing insight into the network's learning progress.**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
